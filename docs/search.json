[
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Our Course Project",
    "section": "",
    "text": "I’m honored to be a member of the [group name] project team.\nBelow, you’ll find a brief summary of our project. To access a detailed project description, please go to https://[your-project-url].\nSummary\n[provide a biref summary of your project]\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Analytics Lab",
    "section": "",
    "text": "LITERALLY ME\n\n\n\n\n\n\n\n\n\n\n\nHello! My name is Onur Yucel.\nThis is my personal webpage.\nPlease stay tuned to follow my works on data analytics, blog posts, and more.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-2.html",
    "href": "assignments/assignment-2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Show the code\n#Required Libraries\nlibrary(tidyverse) # for everything :) \nlibrary(rvest) # for HTML scraping \nlibrary(stringr) # for string processing\n\n#URL's\nURLS &lt;- c(\"https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-12-31&num_votes=2500,&country_of_origin=TR&count=250\" ,\"https://m.imdb.com/search/title/?title_type=feature&release_date=,2009-12-31&num_votes=2500,&country_of_origin=TR&count=250\")\n\n#Scrapping \ndata_html &lt;- read_html(URLS[1])\n\n# extract titles (movie names)\ntitle_names &lt;- data_html |&gt; html_nodes('.ipc-title__text')\ntitle_names &lt;- html_text(title_names)\ntitle_names &lt;- tail(head(title_names,-1),-1)\ntitle_names &lt;- str_split(title_names, \" \", n=2)\ntitle_names &lt;- unlist(lapply(title_names, function(x) {x[2]}))\n\n# extract years \nyears &lt;- data_html |&gt; html_nodes('.sc-300a8231-7:nth-child(1)') |&gt; html_text()\n\n# extract durations \ndurations &lt;- data_html |&gt; html_nodes('.sc-300a8231-7:nth-child(2)') |&gt; html_text()\ndurations &lt;- sapply(durations, function(x) {\n  time_parts &lt;- strsplit(x, \"h|m\")[[1]]\n  as.numeric(time_parts[1]) * 60 + as.numeric(time_parts[2])\n})\n\n#extract rating\nratings &lt;- data_html |&gt; html_nodes('.ipc-rating-star--rating') |&gt; html_text()\n\n#extract votes\nvotes &lt;- data_html %&gt;% html_nodes(\".ipc-rating-star--voteCount\") %&gt;% html_text()\nvotes &lt;- gsub(\"\\\\(|\\\\)| \", \"\", votes)\n\nmovies_data &lt;- data.frame(\n  Title = title_names,\n  Year = years,\n  Duration = durations,\n  Rating = ratings,\n  Votes = votes,\n  stringsAsFactors = FALSE\n)\n\nrownames(movies_data) &lt;- NULL \nprint(movies_data)\n\n\n                      Title Year Duration Rating Votes\n1         Kuru Otlar Üstüne 2023      197    7.7   16K\n2  Yedinci Kogustaki Mucize 2019      132    8.2   58K\n3                    Baskin 2015       97    5.8   13K\n4                Kis Uykusu 2014      196    8.0   57K\n5         Cebimdeki Yabanci 2018       95    6.8   10K\n6                      Ayla 2017      125    8.2   45K\n7   Bir Zamanlar Anadolu'da 2011      157    7.8   51K\n8               Ahlat Agaci 2018      188    8.0   29K\n9   Istanbul Için Son Çagri 2023       91    5.3  9.6K\n10                   Dag II 2016      135    8.2  111K\n11             Kurak Günler 2022      129    7.5   13K\n12      Dabbe: Cin Çarpmasi 2013      134    6.8  7.9K\n13                   Mucize 2015      136    7.6   15K\n14                   Bihter 2023      113    3.6  4.1K\n15                   Siccîn 2014       96    6.0  5.7K\n16           Ölümlü Dünya 2 2023      117    6.8  9.7K\n17             Ölümlü Dünya 2018      107    7.6   33K\n18                     Kedi 2016       79    7.6   16K\n19   The Ottoman Lieutenant 2017      106    6.4   27K\n20                      Dag 2012       90    7.5   24K\n21               Av Mevsimi 2010      140    7.4   38K\n22           Do Not Disturb 2023      114    6.3   11K\n23              Okul Tirasi 2021       85    7.3  3.5K\n24            Aile Arasinda 2017      124    7.6   27K\n25                 Siccin 2 2015       93    6.1  4.2K\n\n\n\n3.a\nMovies and Their Ratings\n\n\nShow the code\nlibrary(dplyr)\nlibrary(ggplot2)\n\n#Convert the datatype of the Rating column \nmovies_data$Rating &lt;- as.numeric(movies_data$Rating)\n\n\nmax_rating &lt;- max(movies_data$Rating, na.rm = TRUE)\nmin_rating &lt;- min(movies_data$Rating, na.rm = TRUE)\nmid_point &lt;- (max_rating + min_rating) / 2\n\nmovies_data_arranged_by_rating &lt;- movies_data %&gt;%\n  arrange(desc(Rating))\n\nggplot(movies_data, aes(x = Rating, y = reorder(Title, Rating), fill = Rating &gt; mid_point)) +\n  geom_segment(aes(x = mid_point, xend = Rating, yend = Title), size = 4) +\n  scale_fill_manual(values = c(\"red\", \"blue\"), labels = c(\"Below Midpoint\", \"Above Midpoint\")) +\n  labs(\n    title = \"Movies and Ratings\",\n    x = \"Rating\",\n    y = \"Movies\",\n    fill = \"Rating Category\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(breaks = seq(min(movies_data$Rating), max(movies_data$Rating), by = 1))  # X ekseninde rating de??erleri\n\n\n\n\n\n\n\n\n\nBest 5 Movies by Rating\n\n\nShow the code\ntop_5_movies &lt;- movies_data %&gt;%\n  arrange(desc(Rating)) %&gt;%\n  head(5)\n\nprint(top_5_movies)\n\n\n                     Title Year Duration Rating Votes\n1 Yedinci Kogustaki Mucize 2019      132    8.2   58K\n2                     Ayla 2017      125    8.2   45K\n3                   Dag II 2016      135    8.2  111K\n4               Kis Uykusu 2014      196    8.0   57K\n5              Ahlat Agaci 2018      188    8.0   29K\n\n\nWorst 5 Movies by Rating.\n\n\nShow the code\nbottom_5_movies &lt;- movies_data %&gt;%\n  arrange(Rating) %&gt;%\n  head(5)\n\nprint(bottom_5_movies)\n\n\n                    Title Year Duration Rating Votes\n1                  Bihter 2023      113    3.6  4.1K\n2 Istanbul Için Son Çagri 2023       91    5.3  9.6K\n3                  Baskin 2015       97    5.8   13K\n4                  Siccîn 2014       96    6.0  5.7K\n5                Siccin 2 2015       93    6.1  4.2K\n\n\n\n\n3.b\nMy Favourite 3 Films\n\n\nShow the code\nlibrary(gt)\n\n#Highlighting my favs\nmy_fav_three_movies &lt;- movies_data_arranged_by_rating |&gt; \n  filter(Title %in% c(\"Av Mevsimi\", \"Bir Zamanlar Anadolu'da\", \"Ahlat Agaci\"))\n\n#Creating the table.\nmovies_data_arranged_by_rating %&gt;%\n  gt() %&gt;%\n  tab_style(\n    style = cell_fill(color = \"yellow\"),\n    locations = cells_body(\n      columns = vars(Title), \n      rows = Title %in% c(\"Av Mevsimi\", \"Bir Zamanlar Anadolu'da\", \"Ahlat Agaci\")\n    )\n  )\n\n\n\n\n\n\n\n\nTitle\nYear\nDuration\nRating\nVotes\n\n\n\n\nYedinci Kogustaki Mucize\n2019\n132\n8.2\n 58K\n\n\nAyla\n2017\n125\n8.2\n 45K\n\n\nDag II\n2016\n135\n8.2\n 111K\n\n\nKis Uykusu\n2014\n196\n8.0\n 57K\n\n\nAhlat Agaci\n2018\n188\n8.0\n 29K\n\n\nBir Zamanlar Anadolu'da\n2011\n157\n7.8\n 51K\n\n\nKuru Otlar Üstüne\n2023\n197\n7.7\n 16K\n\n\nMucize\n2015\n136\n7.6\n 15K\n\n\nÖlümlü Dünya\n2018\n107\n7.6\n 33K\n\n\nKedi\n2016\n79\n7.6\n 16K\n\n\nAile Arasinda\n2017\n124\n7.6\n 27K\n\n\nKurak Günler\n2022\n129\n7.5\n 13K\n\n\nDag\n2012\n90\n7.5\n 24K\n\n\nAv Mevsimi\n2010\n140\n7.4\n 38K\n\n\nOkul Tirasi\n2021\n85\n7.3\n 3.5K\n\n\nCebimdeki Yabanci\n2018\n95\n6.8\n 10K\n\n\nDabbe: Cin Çarpmasi\n2013\n134\n6.8\n 7.9K\n\n\nÖlümlü Dünya 2\n2023\n117\n6.8\n 9.7K\n\n\nThe Ottoman Lieutenant\n2017\n106\n6.4\n 27K\n\n\nDo Not Disturb\n2023\n114\n6.3\n 11K\n\n\nSiccin 2\n2015\n93\n6.1\n 4.2K\n\n\nSiccîn\n2014\n96\n6.0\n 5.7K\n\n\nBaskin\n2015\n97\n5.8\n 13K\n\n\nIstanbul Için Son Çagri\n2023\n91\n5.3\n 9.6K\n\n\nBihter\n2023\n113\n3.6\n 4.1K\n\n\n\n\n\n\n\n\n\n3.c\nAverage Ratings by Year\n\n\nShow the code\nlibrary(dplyr)\n\n# Calculate yearly rating averages\nyearly_rating_averages &lt;- movies_data_arranged_by_rating %&gt;%\n  group_by(Year) %&gt;%\n  summarise(average_rating = mean(as.numeric(Rating), na.rm = TRUE))\n\n# View the result\nprint(yearly_rating_averages)\n\n\n# A tibble: 13 × 2\n   Year  average_rating\n   &lt;chr&gt;          &lt;dbl&gt;\n 1 2010            7.4 \n 2 2011            7.8 \n 3 2012            7.5 \n 4 2013            6.8 \n 5 2014            7   \n 6 2015            6.5 \n 7 2016            7.9 \n 8 2017            7.4 \n 9 2018            7.47\n10 2019            8.2 \n11 2021            7.3 \n12 2022            7.5 \n13 2023            5.94\n\n\n\n\nShow the code\nlibrary(ggplot2)\n\n# Scatter plot of yearly rating averages with line connecting the points\nggplot(yearly_rating_averages, aes(x = Year, y = average_rating)) +\n  geom_point(color = \"blue\") + \n  geom_line(group = 1, color = \"blue\") +  # Adding line connecting the points\n  labs(\n    title = \"Average Movie Ratings Over the Years\",\n    x = \"Year\",\n    y = \"Average Rating\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNumber of Movies per Year\n\n\nShow the code\n# Calculate the number of movies per year\nmovies_per_year &lt;- movies_data_arranged_by_rating %&gt;%\n  group_by(Year) %&gt;%\n  summarise(number_of_movies = n())\n\n# Scatter plot of number of movies per year\nggplot(movies_per_year, aes(x = Year, y = number_of_movies)) +\n  geom_point(color = \"red\") +\n  geom_line(group = 1, color = \"blue\") +\n  labs(\n    title = \"Number of Movies Per Year\",\n    x = \"Year\",\n    y = \"Number of Movies\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nBox Plot of Ratings Over the Years\n\n\nShow the code\n# Box plot of ratings over the years\nggplot(movies_data_arranged_by_rating, aes(x = as.factor(Year), y = as.numeric(Rating))) +\n  geom_boxplot(fill = \"tomato\", color = \"black\") +\n  labs(\n    title = \"Box Plot of Movie Ratings Over the Years\",\n    x = \"Year\",\n    y = \"Rating\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n3.d\nIs there a correlation between Votes and Ratings\n\n\nShow the code\nlibrary(ggplot2)\n\nggplot(movies_data_arranged_by_rating,aes(x = Votes,y = Rating))+\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Assignment 2"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I was born in Trabzon in 2002 but grew up in Bursa. In 2020, I got into Hacettepe Electrical and Electronics Engineering and settled in Ankara. After my two-year undergraduate education, I transferred to the Industrial Engineering department, thinking it was more suitable for me.\nDownload My Resume"
  },
  {
    "objectID": "about.html#employements",
    "href": "about.html#employements",
    "title": "About Me",
    "section": "Employements",
    "text": "Employements"
  },
  {
    "objectID": "about.html#internships",
    "href": "about.html#internships",
    "title": "About Me",
    "section": "Internships",
    "text": "Internships"
  },
  {
    "objectID": "assignments/assignment-1.html",
    "href": "assignments/assignment-1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "My first assignment has two parts.\n\n\nAccording to Mustafa Baydo??an, we, as industrial engineers, frequently encounter optimization problems. There are tools we have learned to solve these problems, the most important of which is mathematical modeling. Recently, methods have started to be taught on the data mining and analysis side.\nAccording to his experience with a company dealing with lumber, as industrial engineers, we can be a bridge between the problem and the solution. From the moment he first heard about the company’s problem, he investigated the problem in detail and tried to understand it. This made those experiencing the problem feel understood. Again, from this story, it is seen that we can work with many different disciplines.\nLater, Mr. Baydo??an talked about the importance of estimating production and consumption in the electricity market and showed us the great damages that wrong estimations will cause. He also explained the differences between deep learning and traditional learning and discussed how to solve these estimation problems.\nHe stated that many applications collect data from us in addition to the service they provide to us and take their positions according to this data.\nFinally, he concluded his words by saying that, in his opinion, the best way to learn is to get our hands dirty and get involved.\nQUESTION 1- What is the correct order of the decision-making process? a) Goal Setting - Determining the Possible Cause of the Problem - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution b) Identifying Alternatives and Selecting the Most Effective Solution - Goal Setting - Collecting the necessary information about the Problem - Determining the Possible Cause of the Problem c) Goal Setting - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution - Determining the Possible Cause of the Problem d) Determining the Possible Cause of the Problem - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution - Goal Setting\nQUESTION 2- What do Industrial Engineers usually deal with in their work? Answer: Industrial engineers frequently encounter optimization problems in their professional lives. They learn various tools to solve these problems, with mathematical modeling being one of them. Problems that cannot be solved through deterministic methods are addressed using statistical or stochastic approaches. In the past decade, data mining has also become one of these essential tools.\n\n\n\nSTEP 1 # We need to install the ‘dslabs’ library and save the polls_us_election_2016.\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nSTEP 2 # Display the first 10 rows.\n\nfirst_ten_rows &lt;- head(polls_us_election_2016,10)\nprint(first_ten_rows)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nSTEP 3 # Calculate and display the total number of NA values in the entire data set. # I used the sum and is.na functions. is.na function returns a 1 or 0 value, and the sum function sums them.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(paste(\"Total NA values:\", total_na))\n\n[1] \"Total NA values: 11604\"\n\n\nSTEP 4 # Replace all NA values in the ???polls_us_election_2016??? data set as follows: For numeric columns, replace NA values with your birth year. For character or factor columns, replace NA values with your first name. Store the modified data set as a new object.\n\nbirth_year &lt;- 2002  \nfirst_name &lt;- \"Onur\" \n\nmodified_data &lt;- polls_us_election_2016\n\nfor (col in names(modified_data)) {\n  if (is.numeric(modified_data[[col]])) \n  {\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- birth_year\n  } \n  else if (is.factor(modified_data[[col]])) \n  {\n    levels(modified_data[[col]]) &lt;- c(levels(modified_data[[col]]), first_name)\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- first_name\n  }\n  else if (is.character(modified_data[[col]])) \n  {\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- first_name\n  }\n}\n\nSTEP 5 # Print the first 10 rows of the new data frame and the total number of NAs remaining in the new data frame.\n\nprint(head(modified_data, 10))\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  Onur       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\nremaining_na &lt;- sum(is.na(modified_data))\ncat(\"Remaining NA values:\", remaining_na, \"\\n\")\n\nRemaining NA values: 0",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "My Assignments",
    "section": "",
    "text": "On this page, I showcase the assignment I conducted for the [term and year, e.g. Fall 2023] EMU 430 Data Analytics course.\nPlease use left menu to navigate through my assignments.\nThe most recent update to this page was made on October 25, 2023\n\n\n\n Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Blog",
    "section": "",
    "text": "This page is under construction.\n\n\n\n Back to top"
  },
  {
    "objectID": "assignments/assignment-1.html#a",
    "href": "assignments/assignment-1.html#a",
    "title": "Assignment 1",
    "section": "",
    "text": "According to Mustafa Baydo??an, we, as industrial engineers, frequently encounter optimization problems. There are tools we have learned to solve these problems, the most important of which is mathematical modeling. Recently, methods have started to be taught on the data mining and analysis side.\nAccording to his experience with a company dealing with lumber, as industrial engineers, we can be a bridge between the problem and the solution. From the moment he first heard about the company’s problem, he investigated the problem in detail and tried to understand it. This made those experiencing the problem feel understood. Again, from this story, it is seen that we can work with many different disciplines.\nLater, Mr. Baydo??an talked about the importance of estimating production and consumption in the electricity market and showed us the great damages that wrong estimations will cause. He also explained the differences between deep learning and traditional learning and discussed how to solve these estimation problems.\nHe stated that many applications collect data from us in addition to the service they provide to us and take their positions according to this data.\nFinally, he concluded his words by saying that, in his opinion, the best way to learn is to get our hands dirty and get involved.\nQUESTION 1- What is the correct order of the decision-making process? a) Goal Setting - Determining the Possible Cause of the Problem - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution b) Identifying Alternatives and Selecting the Most Effective Solution - Goal Setting - Collecting the necessary information about the Problem - Determining the Possible Cause of the Problem c) Goal Setting - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution - Determining the Possible Cause of the Problem d) Determining the Possible Cause of the Problem - Collecting the necessary information about the Problem - Identifying Alternatives and Selecting the Most Effective Solution - Goal Setting\nQUESTION 2- What do Industrial Engineers usually deal with in their work? Answer: Industrial engineers frequently encounter optimization problems in their professional lives. They learn various tools to solve these problems, with mathematical modeling being one of them. Problems that cannot be solved through deterministic methods are addressed using statistical or stochastic approaches. In the past decade, data mining has also become one of these essential tools.",
    "crumbs": [
      "Assignment 1"
    ]
  },
  {
    "objectID": "assignments/assignment-1.html#b",
    "href": "assignments/assignment-1.html#b",
    "title": "Assignment 1",
    "section": "",
    "text": "STEP 1 # We need to install the ‘dslabs’ library and save the polls_us_election_2016.\n\nlibrary(dslabs)\ndata(polls_us_election_2016)\n\nSTEP 2 # Display the first 10 rows.\n\nfirst_ten_rows &lt;- head(polls_us_election_2016,10)\nprint(first_ten_rows)\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  &lt;NA&gt;       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00               NA\n2          lv           38.03         35.69            5.46               NA\n3          lv           42.00         39.00            6.00               NA\n4          lv           45.00         41.00            5.00               NA\n5          rv           47.00         43.00            3.00               NA\n6          lv           48.00         44.00            3.00               NA\n7          lv           45.00         41.00            5.00               NA\n8          lv           44.00         40.00            6.00               NA\n9          lv           46.00         44.00            6.00               NA\n10         lv           41.20         42.70            7.10               NA\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221               NA\n2         43.34557      41.21439        5.175792               NA\n3         42.02638      38.81620        6.844734               NA\n4         45.65676      40.92004        6.069454               NA\n5         46.84089      42.33184        3.726098               NA\n6         49.02208      43.95631        3.057876               NA\n7         45.11649      40.92722        4.341786               NA\n8         43.58576      40.77325        5.365788               NA\n9         44.82594      41.59978        7.870127               NA\n10        42.92745      42.23545        6.316175               NA\n\n\nSTEP 3 # Calculate and display the total number of NA values in the entire data set. # I used the sum and is.na functions. is.na function returns a 1 or 0 value, and the sum function sums them.\n\ntotal_na &lt;- sum(is.na(polls_us_election_2016))\nprint(paste(\"Total NA values:\", total_na))\n\n[1] \"Total NA values: 11604\"\n\n\nSTEP 4 # Replace all NA values in the ???polls_us_election_2016??? data set as follows: For numeric columns, replace NA values with your birth year. For character or factor columns, replace NA values with your first name. Store the modified data set as a new object.\n\nbirth_year &lt;- 2002  \nfirst_name &lt;- \"Onur\" \n\nmodified_data &lt;- polls_us_election_2016\n\nfor (col in names(modified_data)) {\n  if (is.numeric(modified_data[[col]])) \n  {\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- birth_year\n  } \n  else if (is.factor(modified_data[[col]])) \n  {\n    levels(modified_data[[col]]) &lt;- c(levels(modified_data[[col]]), first_name)\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- first_name\n  }\n  else if (is.character(modified_data[[col]])) \n  {\n    modified_data[[col]][is.na(modified_data[[col]])] &lt;- first_name\n  }\n}\n\nSTEP 5 # Print the first 10 rows of the new data frame and the total number of NAs remaining in the new data frame.\n\nprint(head(modified_data, 10))\n\n        state  startdate    enddate\n1        U.S. 2016-11-03 2016-11-06\n2        U.S. 2016-11-01 2016-11-07\n3        U.S. 2016-11-02 2016-11-06\n4        U.S. 2016-11-04 2016-11-07\n5        U.S. 2016-11-03 2016-11-06\n6        U.S. 2016-11-03 2016-11-06\n7        U.S. 2016-11-02 2016-11-06\n8        U.S. 2016-11-03 2016-11-05\n9  New Mexico 2016-11-06 2016-11-06\n10       U.S. 2016-11-04 2016-11-07\n                                                     pollster grade samplesize\n1                                    ABC News/Washington Post    A+       2220\n2                                     Google Consumer Surveys     B      26574\n3                                                       Ipsos    A-       2195\n4                                                      YouGov     B       3677\n5                                            Gravis Marketing    B-      16639\n6  Fox News/Anderson Robbins Research/Shaw & Company Research     A       1295\n7                                     CBS News/New York Times    A-       1426\n8                                NBC News/Wall Street Journal    A-       1282\n9                                                    Zia Poll  Onur       8439\n10                                                   IBD/TIPP    A-       1107\n   population rawpoll_clinton rawpoll_trump rawpoll_johnson rawpoll_mcmullin\n1          lv           47.00         43.00            4.00             2002\n2          lv           38.03         35.69            5.46             2002\n3          lv           42.00         39.00            6.00             2002\n4          lv           45.00         41.00            5.00             2002\n5          rv           47.00         43.00            3.00             2002\n6          lv           48.00         44.00            3.00             2002\n7          lv           45.00         41.00            5.00             2002\n8          lv           44.00         40.00            6.00             2002\n9          lv           46.00         44.00            6.00             2002\n10         lv           41.20         42.70            7.10             2002\n   adjpoll_clinton adjpoll_trump adjpoll_johnson adjpoll_mcmullin\n1         45.20163      41.72430        4.626221             2002\n2         43.34557      41.21439        5.175792             2002\n3         42.02638      38.81620        6.844734             2002\n4         45.65676      40.92004        6.069454             2002\n5         46.84089      42.33184        3.726098             2002\n6         49.02208      43.95631        3.057876             2002\n7         45.11649      40.92722        4.341786             2002\n8         43.58576      40.77325        5.365788             2002\n9         44.82594      41.59978        7.870127             2002\n10        42.92745      42.23545        6.316175             2002\n\nremaining_na &lt;- sum(is.na(modified_data))\ncat(\"Remaining NA values:\", remaining_na, \"\\n\")\n\nRemaining NA values: 0",
    "crumbs": [
      "Assignment 1"
    ]
  }
]